{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('raw_data/precision-experiment-2022-11-09T14_30_34.775Z (2).csv')\n",
    "df = pd.read_csv(\"raw_data/precision-experiment-2023-01-24T17_15_59.068Z.csv\")\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df['events'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_plot_errors(\n",
    "    df, TRIAL_TAG, first_sample=0, max_plots=5, screen_res=(1920, 1080), verbose=True\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (Pandas DataFrame): Data\n",
    "        TRIAL_TAG (str): Type of trial (`validation-stimulus` or `fixation-stimulus`)\n",
    "        first_sample (int, optional): First sample fo evaluate. Useful for filtering. Defaults to 0.\n",
    "        max_plots (int, optional): Max number of plots. Defaults to 5.\n",
    "        screen_res (tuple, optional): Screen Resolution of experiment. Defaults to (1920, 1080).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Analyzed data with columns:\n",
    "            \"trials\": trials\n",
    "            \"presented_point\": presented_points\n",
    "            \"time_between_samples_mean\": time_between_samples_mean\n",
    "            \"time_between_samples_std\": time_between_samples_std\n",
    "            \"sampling_rate_mean\": sampling_rate_mean\n",
    "            \"sampling_rate_std\": sampling_rate_std\n",
    "            \"last_time_sample\": last_time_sample\n",
    "            \"horizontal_errors_pxs_mean\": horizontal_errors_pxs_mean,\n",
    "            \"horizontal_errors_pxs_std\": horizontal_errors_pxs_std,\n",
    "            \"vertical_errors_pxs_mean\": vertical_errors_pxs_mean,\n",
    "            \"vertical_errors_pxs_std\": vertical_errors_pxs_std,\n",
    "            \"total_errors_pxs_mean\": total_errors_pxs_mean,\n",
    "            \"total_errors_pxs_std\": total_errors_pxs_std\n",
    "    \"\"\"\n",
    "    trials = []\n",
    "    presented_points = []\n",
    "    time_between_samples_mean = []\n",
    "    time_between_samples_std = []\n",
    "    sampling_rate_mean = []\n",
    "    sampling_rate_std = []\n",
    "    last_time_sample = []\n",
    "    horizontal_errors_pxs_mean = []\n",
    "    horizontal_errors_pxs_std = []\n",
    "    vertical_errors_pxs_mean = []\n",
    "    vertical_errors_pxs_std = []\n",
    "    total_errors_pxs_mean = []\n",
    "    total_errors_pxs_std = []\n",
    "\n",
    "    center_x = df[df[\"trial-tag\"] == TRIAL_TAG][\"center_x\"].iloc[0]\n",
    "    center_y = df[df[\"trial-tag\"] == TRIAL_TAG][\"center_y\"].iloc[0]\n",
    "\n",
    "    nv = df[df[\"trial-tag\"] == TRIAL_TAG][\"validation-id\"].values\n",
    "    xv = df[df[\"trial-tag\"] == TRIAL_TAG][\"start-x\"].values + center_x\n",
    "    yv = df[df[\"trial-tag\"] == TRIAL_TAG][\"start-y\"].values + center_y\n",
    "\n",
    "    k = 0\n",
    "    for d in df[df[\"trial-tag\"] == TRIAL_TAG][\"webgazer_data\"].map(eval):\n",
    "\n",
    "        xs = []\n",
    "        ys = []\n",
    "        ts = []\n",
    "        for i in d:\n",
    "            xs.append(i[\"x\"])\n",
    "            ys.append(i[\"y\"])\n",
    "            ts.append(i[\"t\"])\n",
    "\n",
    "        trials.append(nv[k])\n",
    "        presented_points.append((xv[k], yv[k]))\n",
    "        time_between_samples_mean.append(np.mean(np.diff(ts)))\n",
    "        time_between_samples_std.append(np.std(np.diff(ts)))\n",
    "        sampling_rate_mean.append(np.mean(1000 / np.diff(ts)))\n",
    "        sampling_rate_std.append(np.std(1000 / np.diff(ts)))\n",
    "        last_time_sample.append(max(ts))\n",
    "\n",
    "        xs = np.array(xs)\n",
    "        ys = np.array(ys)\n",
    "        ts = np.array(ts)\n",
    "\n",
    "        xs = xs[ts > first_sample]\n",
    "        ys = ys[ts > first_sample] \n",
    "        ts = ts[ts > first_sample]\n",
    "\n",
    "        ex = abs(xs - xv[k])\n",
    "        ey = abs(ys - yv[k])\n",
    "        ee = np.sqrt(ex**2 + ey**2)\n",
    "\n",
    "        horizontal_errors_pxs_mean.append(np.mean(ex))\n",
    "        horizontal_errors_pxs_std.append(np.std(ex))\n",
    "        vertical_errors_pxs_mean.append(np.mean(ey))\n",
    "        vertical_errors_pxs_std.append(np.std(ey))\n",
    "        total_errors_pxs_mean.append(np.mean(ee))\n",
    "        total_errors_pxs_std.append(np.std(ee))\n",
    "\n",
    "        gs = gridspec.GridSpec(2, 4)\n",
    "        gs.update(wspace=2)\n",
    "        ax1 = plt.subplot(\n",
    "            gs[0, :2],\n",
    "        )\n",
    "        ax1.set_title(\"Gaze estimation\")\n",
    "        ax1.scatter(xv[k], yv[k], c=\"c\")\n",
    "        ax1.vlines(screen_res[0] / 2, 0, screen_res[1], \"k\")\n",
    "        ax1.hlines(screen_res[1] / 2, 0, screen_res[0], \"k\")\n",
    "        colored_plot = ax1.scatter(xs, ys, c=ts)\n",
    "        plt.colorbar(colored_plot, ax=ax1)\n",
    "        ax1.scatter(xv[k], yv[k], c=\"b\")\n",
    "        ax1.set_xlim(0, screen_res[0])\n",
    "        ax1.set_ylim(0, screen_res[1])\n",
    "\n",
    "        ax2 = plt.subplot(gs[0, 2:])\n",
    "        ax2.set_title(\"X coordinate over time\")\n",
    "        ax2.plot(ts, xs, \"k.\")\n",
    "        ax2.set_ylim(0, center_x * 2)\n",
    "        ax2.hlines(center_x, 0, max(ts), \"k\")\n",
    "\n",
    "        ax3 = plt.subplot(gs[1, 1:3])\n",
    "        ax3.set_title(\"y coordinate over time\")\n",
    "        ax3.plot(ts, ys, \"k.\")\n",
    "        ax3.set_ylim(0, center_y * 2)\n",
    "        ax3.hlines(center_y, 0, max(ts), \"k\")\n",
    "\n",
    "        if verbose:\n",
    "            plt.show()\n",
    "            print(\"Horizontal error (pxs) = %.0f +- %.0f \" % (np.mean(ex), np.std(ex)))\n",
    "            print(\"Vertical error (pxs) = %.0f +- %.0f \" % (np.mean(ey), np.std(ey)))\n",
    "            print(\"Total error (pxs) = %.0f +- %.0f \" % (np.mean(ee), np.std(ee)))\n",
    "            print(\"Validation point (%d): %d, %d\" % (nv[k], xv[k], yv[k]))\n",
    "            print(\n",
    "                \"Time between samples (ms) = %.0f +- %.0f \"\n",
    "                % (np.mean(np.diff(ts)), np.std(np.diff(ts)))\n",
    "            )\n",
    "            print(\n",
    "                \"Sampling rate (Hz) = %.0f +- %.0f \"\n",
    "                % (np.mean(1000 / np.diff(ts)), np.std(1000 / np.diff(ts)))\n",
    "            )\n",
    "            print(\"Last time sample = %d\" % max(ts))\n",
    "\n",
    "        print(\"k:\", k)\n",
    "        k += 1\n",
    "        if k == max_plots:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"trials\": trials,\n",
    "            \"presented_point\": presented_points,\n",
    "            \"time_between_samples_mean\": time_between_samples_mean,\n",
    "            \"time_between_samples_std\": time_between_samples_std,\n",
    "            \"sampling_rate_mean\": sampling_rate_mean,\n",
    "            \"sampling_rate_std\": sampling_rate_std,\n",
    "            \"last_time_sample\": last_time_sample,\n",
    "            \"horizontal_errors_pxs_mean\": horizontal_errors_pxs_mean,\n",
    "            \"horizontal_errors_pxs_std\": horizontal_errors_pxs_std,\n",
    "            \"vertical_errors_pxs_mean\": vertical_errors_pxs_mean,\n",
    "            \"vertical_errors_pxs_std\": vertical_errors_pxs_std,\n",
    "            \"total_errors_pxs_mean\": total_errors_pxs_mean,\n",
    "            \"total_errors_pxs_std\": total_errors_pxs_std,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_TAG = 'validation-stimulus'\n",
    "# TRIAL_TAG = \"fixation-stimulus\"  # Es el momento donde aparece la cruz de fijacion\n",
    "\n",
    "df_res = calculate_and_plot_errors(df, TRIAL_TAG,first_sample=300, max_plots=10, verbose=True)\n",
    "print(f\"Error: {df_res['total_errors_pxs_mean'].mean():.2f} +- {df_res['total_errors_pxs_mean'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Error: {df_res['total_errors_pxs_mean'].mean():.2f} +- {df_res['total_errors_pxs_mean'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Error: {df_res['total_errors_pxs_mean'].mean():.2f} +- {df_res['total_errors_pxs_mean'].std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('et_precision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f0d42c22a5736a7a0eed5c53d5493904972f3860a3efc761472d071d7e111ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
